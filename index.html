<html>
<body>
	<a id="download">Download</a>
	<button id="stop">Stop</button>
	<script>
	  const audioCtx = new AudioContext();
	  var originAudioBuffer;
	  let duration = 0; //messy
	  async function load() {	  	
	  	const response = await fetch('sample.mp3');
  		const arrayBuffer = await response.arrayBuffer();
  		originAudioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
  		duration = originAudioBuffer.duration; //messy
	  	const trackSource = audioCtx.createBufferSource();
  		trackSource.buffer = originAudioBuffer;
  		trackSource.connect(audioCtx.destination);
  		return trackSource;
	  }
	  async function handleMicrophoneSuccess(stream) {
		  let trackSource = await load();
	  	trackSource.addEventListener('ended', () => {
	  		mediaRecorder.stop();
	  	});
      const trackAnal = audioCtx.createAnalyser();
      trackAnal.maxDecibels = 0;
      const trackProcessor = audioCtx.createScriptProcessor(1024, 1, 1);
      let trackAmplitudeArray = new Uint8Array(trackAnal.frequencyBinCount);
      trackSource.connect(trackAnal);
      trackAnal.connect(trackProcessor);
      let trackMax = 0;
      trackProcessor.onaudioprocess = function() {
        //console.log('processing'); //works
        //anal.getByteTimeDomainData(amplitudeArray);
        trackAnal.getByteFrequencyData(amplitudeArray);
        //console.log(amplitudeArray);
        let sampleMax = amplitudeArray.reduce((a,b) => Math.max(a,b));
        trackMax  = Math.max(trackMax,sampleMax);
        //console.log(trackMax);
      }

      const streamSource = audioCtx.createMediaStreamSource(stream);
      const anal = audioCtx.createAnalyser();
      anal.maxDecibels = 0;
      anal.smoothingTimeConstant
      const processor = audioCtx.createScriptProcessor(1024, 1, 1);
      let amplitudeArray = new Uint8Array(anal.frequencyBinCount);
      streamSource.connect(anal);
      anal.connect(processor);
      let max = 0;
      processor.onaudioprocess = function() {
        //console.log('processing'); //works
        //anal.getByteTimeDomainData(amplitudeArray);
        anal.getByteFrequencyData(amplitudeArray);
        //console.log(amplitudeArray);
        let sampleMax = amplitudeArray.reduce((a,b) => Math.max(a,b));
        max  = Math.max(max,sampleMax);
        console.log(max);
      }

	  	const options = {mimeType: 'audio/webm'};
	  	const recordedChunks = [];
	  	const mediaRecorder = new MediaRecorder(stream, options);

	  	mediaRecorder.addEventListener('dataavailable', async function(e) { //assuming this event only happens after recording ends
	      if (e.data.size > 0) {
	        recordedChunks.push(e.data);
	      }
	      const recordedChunksBlob = new Blob(recordedChunks);
	      const offlineAudioCtx = new OfflineAudioContext(1, duration*48000, 48000);
	      const originTrackSource = offlineAudioCtx.createBufferSource();
	      originTrackSource.buffer = trackSource.buffer;
	      originTrackSource.connect(offlineAudioCtx.destination);

	      const recordedArrayBuffer = await recordedChunksBlob.arrayBuffer();
	  	  const recordedAudioBuffer = await audioCtx.decodeAudioData(recordedArrayBuffer);
		    const recordedTrackSource = offlineAudioCtx.createBufferSource();
	  	  recordedTrackSource.buffer = recordedAudioBuffer;
	  	  recordedTrackSource.connect(offlineAudioCtx.destination);

	  	  originTrackSource.start();
	  	  recordedTrackSource.start();
	  	  const render = await offlineAudioCtx.startRendering();
	  	  const mixRawData = render.getChannelData(0);
	  	  const mixDataBlob = new Blob(mixRawData);
	  	  var mix = audioCtx.createBufferSource();
	  	  mix.buffer = render;
	  	  mix.connect(audioCtx.destination);
	  	  mix.start();
		  });

  	  mediaRecorder.start();
      trackSource.start();

	  };

	  navigator.mediaDevices.getUserMedia({ audio: true, video: false }).then(handleMicrophoneSuccess);
	</script>


</body>
</html>